#!/bin/bash
#centos8.4
#kubadm安装k8s

# 定义变量
nodes=("192.168.44.10" "192.168.44.11" "192.168.44.12")
user="root"
password="1"
yum install -y sshpass
echo "配置免密"
# 检查是否已存在 SSH 密钥对
if [ ! -f ~/.ssh/id_rsa ]; then
  echo "生成 SSH 密钥对..."
  ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa
else
  echo "SSH 密钥对已存在，跳过生成步骤。"
fi

# 分发公钥到每个节点
for node in "${nodes[@]}"; do
  echo "正在将公钥发送到 $node..."
  sshpass -p "$password" ssh-copy-id -o StrictHostKeyChecking=no "$user@$node"
  if [ $? -eq 0 ]; then
    echo "成功将公钥发送到 $node。"
  else
    echo "无法将公钥发送到 $node，请检查连接或权限。"
  fi
done

#!/bin/bash



# 遍历每个节点
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."

# 使用 SSH 执行命令
  ssh root@$node <<'END_SSH'
  yum install -y chrony.x86_64
    # 追加内容到 /etc/hosts
    cat <<EOF >> /etc/hosts
192.168.44.10 master
192.168.44.11 node1
192.168.44.12 node2
EOF

# 关闭防火墙
systemctl stop firewalld
systemctl disable firewalld

# 关闭 SELinux
setenforce 0
sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config

# 关闭 swap
swapoff -a
sed -i "s/^.*swap/#&/g" /etc/fstab

# 清空 iptables
iptables -F
END_SSH

  # 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "1节点 $node 配置成功。"
  else
    echo "1节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 配置时钟源（master）
cp /etc/chrony.conf /etc/chrony.conf.bak
cat <<EOF > /etc/chrony.conf
server master iburst
driftfile /var/lib/chrony/drift
makestep 1.0 3
rtcsync
allow 192.168.44.0/24
local stratum 10
keyfile /etc/chrony.keys
leapsectz right/UTC
logdir /var/log/chrony
EOF
systemctl enable chronyd.service
systemctl start chronyd.service

# 配置时钟源（node）
for node in "${nodes[@]:1}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
cp /etc/chrony.conf /etc/chrony.conf.bak
cat <<'EOF2' > /etc/chrony.conf
server master iburst
driftfile /var/lib/chrony/drift
makestep 1.0 3
rtcsync
keyfile /etc/chrony.keys
leapsectz right/UTC
logdir /var/log/chrony
EOF2
systemctl enable chronyd.service
systemctl start chronyd.service
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "2节点 $node 配置成功。"
  else
    echo "2节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 开启网桥转发（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
sed -i 's/net.ipv4.ip_forward=0/net.ipv4.ip_forward=1/g' /etc/sysctl.conf
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
EOF
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "3节点 $node 配置成功。"
  else
    echo "3节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 安装docker-ce（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
yum install -y yum-utils.noarch  
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum list docker-ce --showduplicates | sort -r
yum install -y docker-ce
systemctl enable docker
systemctl restart docker
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "4节点 $node 配置成功。"
  else
    echo "4节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 配置端点服务（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
cat <<EOF > /etc/crictl.yaml 
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 5
debug: false
EOF
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "5节点 $node 配置成功。"
  else
    echo "5节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 修改cgroup类型（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
containerd config default > /etc/containerd/config.toml
sed -i "s#registry.k8s.io/pause#registry.aliyuncs.com/google_containers/pause#g" /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
systemctl restart containerd
systemctl enable containerd
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "6节点 $node 配置成功。"
  else
    echo "6节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 配置k8s 源（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key
EOF
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "7节点 $node 配置成功。"
  else
    echo "7节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

# 安装集群工具（所有）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
yum install -y kubelet-1.30.0 kubeadm-1.30.0 kubectl-1.30.0 --disableexcludes=kubernetes
systemctl enable --now kubelet.servicce
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "8节点 $node 配置成功。"
  else
    echo "8节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done


# 通过kubeadm初始化集群（master）
for node in "${nodes[@]}"; do
  echo "正在配置节点 $node..."
ssh root@$node <<'END_SSH'
systemctl restart containerd docker
END_SSH
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "9节点 $node 配置成功。"
  else
    echo "9节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done

kubeadm init \
 --image-repository registry.aliyuncs.com/google_containers \
 --kubernetes-version=v1.30.0\
 --pod-network-cidr=10.244.0.0/16



#将其他节点加入集群
echo "Joining node to the cluster..."
for node in "${nodes[@]:1}"; do
  echo "Joining node $node to the cluster..."
  JOIN_COMMAND=$(kubeadm token create --print-join-command)
  # 使用 SSH 执行加入命令
  ssh "root@$node" "$JOIN_COMMAND"
# 检查命令是否执行成功
  if [ $? -eq 0 ]; then
    echo "10节点 $node 配置成功。"
  else
    echo "10节点 $node 配置失败，请检查连接或权限。"
  fi

  echo "----------------------------------------"
done


# 配置环境变量（master）
 mkdir -p $HOME/.kube
 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 sudo chown $(id -u):$(id -g) $HOME/.kube/config
 echo 'export KUBECONFIG=/etc/kubernetes/admin.conf' >> /etc/profile
 echo "source <(kubectl completion bash)" >> /etc/profile

#配置网络节点
wget  https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml
wget  https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/custom-resources.yaml
sed -i 's/cidr: 192.168.0.0\/16/cidr: 10.244.0.0\/16/' custom-resources.yaml
kubectl create -f tigera-operator.yaml
kubectl create -f custom-resources.yaml